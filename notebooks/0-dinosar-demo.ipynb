{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pangeo demo: dinoSAR data\n",
    "\n",
    "This is a simple demo for AGU2018, using InSAR processing output from dinoSAR (https://github.com/scottyhq/dinosar).\n",
    "\n",
    "To run each code cell, use 'shift+enter'\n",
    "\n",
    "**Warning!** you can modify this notebook, upload files, and save files listed on the left (right-click and you will see a download option). BUT!... it is an ephemeral demo. Work will be lost if you leave this idle for a bit. Everything shuts down automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import python packages\n",
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import hvplot.xarray\n",
    "import hvplot.pandas\n",
    "import holoviews as hv\n",
    "import gcsfs\n",
    "import intake\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os.path\n",
    "import s3fs\n",
    "from dask_kubernetes import KubeCluster\n",
    "from dask.distributed import Client\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch a Kubernetes Cluster\n",
    "\n",
    "We can use a kubernetes cluster to increase our computational resources. Note that our final geocoded dataset for this example is pretty small. So we don't actually need a large cluster, but we'll use it anyways to illustrate how it works!\n",
    "\n",
    "10 workers are selected by default (each w/ customizable CPUs and RAM). When parallizeable computations are requested, you'll see the cluster activity on the right hand dashboards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = KubeCluster(n_workers=4)\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List files on AWS S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'stac-uniongap/D115'\n",
    "\n",
    "# This creates a virtual local file listing\n",
    "fs = s3fs.S3FileSystem(anon=True)\n",
    "pairs = fs.ls(bucket)\n",
    "\n",
    "print('Number of images:', len(pairs))\n",
    "print('First images:', pairs[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each of these images has an associates public URL:\n",
    "# We'll use pandas to make a sorted dataframe of all the images\n",
    "def parse_name(s3Path, key='date1'):\n",
    "    ''' grab project, bucket, date1, date2, format from file name, return dictionary'''\n",
    "    pattern = '{project}/{orbit}/int-{date1:%Y%m%d}-{date2:%Y%m%d}/{cog}'\n",
    "    parsed = intake.source.utils.reverse_format(pattern, s3Path)\n",
    "    val = parsed[key]\n",
    "    return val\n",
    "\n",
    "def make_dataframe(images):\n",
    "    ''' organize pandas dataframe by parsing filename'''\n",
    "    df = pd.DataFrame(dict(s3=images))\n",
    "    df = df.sort_values('s3').reset_index(drop=True)\n",
    "    df['url'] = 'http://s3.amazonaws.com/' + df.s3.str[:] \n",
    "    df['date1'] = df.s3.apply(parse_name, args=('date1',))\n",
    "    df['date2'] = df.s3.apply(parse_name, args=('date2',))\n",
    "    df['dt'] = df.date1 - df.date2\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image='unwrapped-phase-cog.tif'\n",
    "images = [os.path.join(x,image) for x in pairs[1:]]\n",
    "\n",
    "df = make_dataframe(images)\n",
    "print('Total images:', len(df))\n",
    "print('First date:', df.date2.iloc[0])\n",
    "print('Last date:', df.date1.iloc[-1])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Cloud-optimized geotiffs (COGs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rasterio uses the gdal vsicurl system to access files\n",
    "# on a cloud server\n",
    "env = rasterio.Env(GDAL_DISABLE_READDIR_ON_OPEN='EMPTY_DIR',\n",
    "                  CPL_VSIL_CURL_USE_HEAD=False,\n",
    "                  CPL_VSIL_CURL_ALLOWED_EXTENSIONS='TIF',\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the first file in the set of images into xarray DataArray (w/ dask)\n",
    "# note this is very fast b/c only metadata is downloaded to local memory\n",
    "# chunks are based on cloud-optimized geotiff internal tiling\n",
    "xchunk = 512\n",
    "ychunk = 512\n",
    "with env:\n",
    "    da = xr.open_rasterio(df.url[0], parse_coordinates=True, chunks={'band': 1, 'x': xchunk, 'y': ychunk})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an xarray DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since all these images are pre-aligned ('analysis ready')\n",
    "# we get best performance loading w/o metadata & coordinate checking\n",
    "def create_dataset(df, chunks={'band': 1, 'x': 512, 'y': 512}):\n",
    "    # Note: this takes a minute b/c coordinate alignment is checked\n",
    "    from ipywidgets import IntProgress\n",
    "    from IPython.display import display\n",
    "    probar = IntProgress(value=0, min=0, max=len(df), step=1, \n",
    "                         description='Loading:')\n",
    "    display(probar)\n",
    "    #print(rasterio.env.getenv())\n",
    "    datasets = []\n",
    "    # Create dataset to fill based on first image\n",
    "    da = xr.open_rasterio(df.url[0], \n",
    "                          parse_coordinates=True, \n",
    "                          chunks=chunks) \n",
    "    probar.value += 1\n",
    "    datasets.append(da.to_dataset(name='unw'))\n",
    "    \n",
    "    # Loop over remaining images to fill array\n",
    "    for i,row in df[1:].iterrows():\n",
    "        probar.value += 1\n",
    "        url = row.url\n",
    "        \n",
    "        try:\n",
    "            da = xr.open_rasterio(url, parse_coordinates=False, chunks=chunks)\n",
    "        except:\n",
    "            #print(f'Error loading {url}')\n",
    "            pass\n",
    "        datasets.append(da.to_dataset(name='unw'))\n",
    "    \n",
    "    ds = xr.concat(datasets, dim='band')\n",
    "    ds.coords['band'] = np.arange(len(df))\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with env:\n",
    "    DS = create_dataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive visualization with holoviews\n",
    "\n",
    "**NOTE:** you may need to resize this pane to see all the buttons (drag grey separator bar to the right)\n",
    "\n",
    "* Once in an xarray DataSet, hvplot can easily display images interactively:\n",
    "* Note column of buttons on upper right side of figure.\n",
    "* In addition to buttons, there is a time slider for band selection\n",
    "    * click slider button and use arrow keys for fine control\n",
    "* Box zoom button updates displayed resolution on the fly\n",
    "* Moving cursor over image gives coordinates and unwrapped phase value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = DS.hvplot('x', 'y', groupby='band', dynamic=True, rasterize=True, \n",
    "                      width=700, height=500, cmap='magma')\n",
    "\n",
    "limits = hv.streams.RangeXY(source=img)\n",
    "\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save current view / subset\n",
    "\n",
    "We can save a local copy of the current image with a function.\n",
    "\n",
    "* select band=1 in interactive image browser above\n",
    "    * zoom into volcano deformation zone in south (bright area)\n",
    "        * run 2 cells below to save the local image subset\n",
    "            * a geotiff will appear in the file browser on the left\n",
    "                * right click the file and select 'download to get it on your laptop'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_src(img):\n",
    "    ''' get current image displayed '''\n",
    "    image_no = img.callback.args\n",
    "    image_url = df.url.iloc[image_no]\n",
    "\n",
    "    return image_url\n",
    "\n",
    "\n",
    "def get_window(img,src):\n",
    "    ''' get current rasterio window from holoviews plot '''\n",
    "    limits = img.streams[1]\n",
    "    if limits.x_range == None:\n",
    "        bounds = src.bounds\n",
    "    else:\n",
    "        bounds = (limits.x_range[0], limits.y_range[0], limits.x_range[1], limits.y_range[1])\n",
    "    uly,ulx = src.index(bounds[0], bounds[3])\n",
    "    lry,lrx = src.index(bounds[2], bounds[1])\n",
    "\n",
    "    width = lrx - ulx\n",
    "    height = lry - uly\n",
    "\n",
    "    return rasterio.windows.Window(ulx, uly, width, height)\n",
    "\n",
    "def save_current_view(img, name='local-image.tif'):\n",
    "    from ipywidgets import IntProgress\n",
    "    from IPython.display import display\n",
    "    probar = IntProgress(value=0, min=0, max=4, step=1, \n",
    "                         description='Saving:')\n",
    "    display(probar)     \n",
    "    \n",
    "    with env:\n",
    "        image_url = get_src(img)\n",
    "        print(f'Saving {image_url}...')\n",
    "        with rasterio.open(image_url) as src:\n",
    "            probar.value +=1\n",
    "            profile = src.profile.copy()\n",
    "            window = get_window(img, src)\n",
    "            print(window)\n",
    "            win_transform = src.window_transform(window)\n",
    "            probar.value +=1\n",
    "            data = src.read(1, window=window)\n",
    "        \n",
    "        profile.update({\n",
    "                'dtype': 'float32',\n",
    "                'height': data.shape[0],\n",
    "                'width': data.shape[1],\n",
    "                'blockxsize': 128,\n",
    "                'blockysize': 128,\n",
    "                'transform': win_transform})  \n",
    "        probar.value += 1\n",
    "        localname = 'subset-' + os.path.basename(src.name)\n",
    "        with rasterio.open(localname, 'w', **profile) as dst:\n",
    "            dst.write_band(1, data) \n",
    "    probar.value +=1\n",
    "    \n",
    "    return localname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "localname = save_current_view(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and plot the saved subset to verify it's the same\n",
    "# Since this is only a single file, we won't load with dask\n",
    "print(localname)\n",
    "with env:\n",
    "    with rasterio.open(localname) as src:\n",
    "        print(src.profile)\n",
    "        da = xr.open_rasterio(src.name)\n",
    "da.hvplot('x', 'y', groupby='band', dynamic=True, rasterize=True, \n",
    "          width=700, height=500, cmap='magma')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel computations\n",
    "\n",
    "With xarray DataSets, we can do parallel computations on the KubeCluster, using dask behind the scenes. Here is a simple example getting the mean phase value for each interferogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xarray_selection(img, band=False):\n",
    "    ''' get selection dictionary from hvplot'''\n",
    "    selection = {}\n",
    "    selection['x'] = slice(*limits.x_range)\n",
    "    selection['y'] = slice(*limits.y_range[::-1])\n",
    "    if band:\n",
    "        selection['band'] = [img.callback.args[0],]\n",
    "    return selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset chunks after selection for better performance\n",
    "ds = DS.sel(get_xarray_selection(img))\n",
    "ds = ds.chunk(dict(band=249,x=721,y=720)) #dimensions (249, 720, 721)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Stack\n",
    "# NOTE: haven't normalized to common reference point, this is just for illustration purposes\n",
    "stack = ds.mean(dim='band')\n",
    "stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep in distributed cluster memory\n",
    "ds_stack = stack.persist() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_stack.unw.plot.imshow(center=False, cmap='magma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all values of pixel at a specfic lon,lat\n",
    "# compute pulls from distributed memory to local RAM\n",
    "xcen = -120.46\n",
    "ycen = 46.5275\n",
    "ts = ds.sel(x=xcen, y=ycen, method='nearest').compute()\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = ts.unw.to_series()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot this\n",
    "# Holoviews is also great for interative 2D plots\n",
    "\n",
    "#line = s.hvplot(width=700, height=300, legend=False)\n",
    "points = s.hvplot.scatter(width=700, height=300, legend=False)\n",
    "label = f'Unwrapped LOS Phase [rad]: easting={xcen:g} , northing={ycen:g}'\n",
    "\n",
    "#(line * points).relabel(label)\n",
    "points.relabel(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data from plot can easily be saved to a CSV\n",
    "#points.data.to_csv()\n",
    "#or\n",
    "s.to_csv('time-series.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of band index, use time index to illustrate group-by. Use date1\n",
    "index = pd.DatetimeIndex(df.date1)\n",
    "DS.band.values=index\n",
    "DS = DS.rename(dict(band='time'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pRef = (-120.46225,  46.53021)\n",
    "xref,yref = pRef\n",
    "#refMean = DS.sel(dict(x=xref,y=yref), method='nearest').compute()\n",
    "\n",
    "pad = 0.001\n",
    "reference = dict(x=slice(xref-pad, xref+pad),\n",
    "                 y=slice(yref+pad, yref-pad))\n",
    "refMean = DS.sel(**reference).mean(dim=['x','y']).compute()\n",
    "\n",
    "refMean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subregion and convert to mm LOS displacement\n",
    "aoi = dict(x=slice(-120.48, -120.46), y=slice(46.54, 46.52))\n",
    "DSnorm = (DS - refMean).sel(aoi) * 5546576/12.5663706\n",
    "DSnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annual = DSnorm.groupby('time.year').mean(dim='time')\n",
    "fg = annual.unw.plot(x='x', y='y', col='year', col_wrap=2, center=False,cmap='plasma')#,vmin=-40,vmax=0)\n",
    "plt.plot(xref, yref, 'wo')\n",
    "_ = plt.text(xref, yref, 'Ref')\n",
    "#plt.title('Annual Stacks [mm LOS]')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
